dftest<-test_xg
dftest2<-dftest
output_vector_train<-dftrain$supernaturalBelief
output_vector_test<-dftest$supernaturalBelief
TrainData <- sparse.model.matrix(supernaturalBelief~.-1,data = dftrain)
TestData <- sparse.model.matrix(supernaturalBelief~.-1,data = dftest)
dtrain <- xgb.DMatrix(data = TrainData, label=output_vector_train)
dtest <- xgb.DMatrix(data = TestData, label=output_vector_test)
watchlist <- list(train=dtrain, test=dtest)
Model2 <- xgb.train(data=dtrain, max.depth=10, eta=1, nthread = 2, nrounds=8, watchlist=watchlist, objective = "reg:linear")
pred <- predict(Model2, TestData)
plot(pred,output_vector_test)
cor.test(pred,output_vector_test)$estimate^2
importance <- xgb.importance(feature_names = TrainData@Dimnames[[2]], model = Model2)
#write.csv(as.data.frame(importance[,1:2]),file = "Table_Pred_sick_leave_Health.issue_size.establishment_year.csv",row.names = F)
xgb.plot.importance(importance_matrix = importance)
head(importance)
View(trimmed_data)
trimmed_data2 <- trimmed_data[, c(1:25)]
df<- data.table(trimmed_data2)
trimmed_data2 <- trimmed_data[, c(1:25)]
df<- data.table(trimmed_data2)
head(df[,godCat:= as.factor(ifelse(godBelief > 0, "believer", "nonbeliever"))])
DF3<-df
train_xg <- df[1:15000,]
test_xg <- df[15001:20000,]
dftrain<-train_xg
dftest<-test_xg
dftest2<-dftest
output_vector_train<-dftrain$godBelief
output_vector_test<-dftest$godBelief
TrainData <- sparse.model.matrix(godBelief~.-1,data = dftrain)
TestData <- sparse.model.matrix(godBelief~.-1,data = dftest)
dtrain <- xgb.DMatrix(data = TrainData, label=output_vector_train)
dtest <- xgb.DMatrix(data = TestData, label=output_vector_test)
watchlist <- list(train=dtrain, test=dtest)
Model2 <- xgb.train(data=dtrain, max.depth=10, eta=1, nthread = 2, nrounds=8, watchlist=watchlist, objective = "reg:linear")
pred <- predict(Model2, TestData)
plot(pred,output_vector_test)
cor.test(pred,output_vector_test)$estimate^2
importance <- xgb.importance(feature_names = TrainData@Dimnames[[2]], model = Model2)
#write.csv(as.data.frame(importance[,1:2]),file = "Table_Pred_sick_leave_Health.issue_size.establishment_year.csv",row.names = F)
xgb.plot.importance(importance_matrix = importance)
head(importance)
trimmed_data2 <- trimmed_data[, c(1:25)]
df<- data.table(trimmed_data2)
#head(df[,godCat:= as.factor(ifelse(godBelief > 0, "believer", "nonbeliever"))])
DF3<-df
train_xg <- df[1:15000,]
test_xg <- df[15001:20000,]
dftrain<-train_xg
dftest<-test_xg
dftest2<-dftest
output_vector_train<-dftrain$godBelief
output_vector_test<-dftest$godBelief
TrainData <- sparse.model.matrix(godBelief~.-1,data = dftrain)
TestData <- sparse.model.matrix(godBelief~.-1,data = dftest)
dtrain <- xgb.DMatrix(data = TrainData, label=output_vector_train)
dtest <- xgb.DMatrix(data = TestData, label=output_vector_test)
watchlist <- list(train=dtrain, test=dtest)
Model2 <- xgb.train(data=dtrain, max.depth=10, eta=1, nthread = 2, nrounds=8, watchlist=watchlist, objective = "reg:linear")
pred <- predict(Model2, TestData)
plot(pred,output_vector_test)
cor.test(pred,output_vector_test)$estimate^2
importance <- xgb.importance(feature_names = TrainData@Dimnames[[2]], model = Model2)
#write.csv(as.data.frame(importance[,1:2]),file = "Table_Pred_sick_leave_Health.issue_size.establishment_year.csv",row.names = F)
xgb.plot.importance(importance_matrix = importance)
trimmed_data2 <- trimmed_data[, c(1:24,26)]
df<- data.table(trimmed_data2)
#head(df[,superCat:= as.factor(ifelse(supernaturalBelief > 0, "believer", "nonbeliever"))])
DF3<-df
train_xg <- df[1:15000,]
test_xg <- df[15001:20000,]
dftrain<-train_xg
dftest<-test_xg
dftest2<-dftest
output_vector_train<-dftrain$supernaturalBelief
output_vector_test<-dftest$supernaturalBelief
TrainData <- sparse.model.matrix(supernaturalBelief~.-1,data = dftrain)
TestData <- sparse.model.matrix(supernaturalBelief~.-1,data = dftest)
dtrain <- xgb.DMatrix(data = TrainData, label=output_vector_train)
dtest <- xgb.DMatrix(data = TestData, label=output_vector_test)
watchlist <- list(train=dtrain, test=dtest)
Model2 <- xgb.train(data=dtrain, max.depth=10, eta=1, nthread = 2, nrounds=8, watchlist=watchlist, objective = "reg:linear")
pred <- predict(Model2, TestData)
plot(pred,output_vector_test)
cor.test(pred,output_vector_test)$estimate^2
importance <- xgb.importance(feature_names = TrainData@Dimnames[[2]], model = Model2)
#write.csv(as.data.frame(importance[,1:2]),file = "Table_Pred_sick_leave_Health.issue_size.establishment_year.csv",row.names = F)
xgb.plot.importance(importance_matrix = importance)
head(importance)
# now without cognitive inhibition
# and ontological and god belief
trimmed_data2 <- trimmed_data[, c(1:20,22,24,26)]
df<- data.table(trimmed_data2)
#head(df[,superCat:= as.factor(ifelse(supernaturalBelief > 0, "believer", "nonbeliever"))])
DF3<-df
train_xg <- df[1:15000,]
test_xg <- df[15001:20000,]
dftrain<-train_xg
dftest<-test_xg
dftest2<-dftest
output_vector_train<-dftrain$supernaturalBelief
output_vector_test<-dftest$supernaturalBelief
TrainData <- sparse.model.matrix(supernaturalBelief~.-1,data = dftrain)
TestData <- sparse.model.matrix(supernaturalBelief~.-1,data = dftest)
dtrain <- xgb.DMatrix(data = TrainData, label=output_vector_train)
dtest <- xgb.DMatrix(data = TestData, label=output_vector_test)
watchlist <- list(train=dtrain, test=dtest)
Model2 <- xgb.train(data=dtrain, max.depth=10, eta=1, nthread = 2, nrounds=8, watchlist=watchlist, objective = "reg:linear")
pred <- predict(Model2, TestData)
plot(pred,output_vector_test)
cor.test(pred,output_vector_test)$estimate^2
importance <- xgb.importance(feature_names = TrainData@Dimnames[[2]], model = Model2)
#write.csv(as.data.frame(importance[,1:2]),file = "Table_Pred_sick_leave_Health.issue_size.establishment_year.csv",row.names = F)
xgb.plot.importance(importance_matrix = importance)
head(importance)
linReg_GB2 <- lm(godBelief ~ PRESENCE_OF_A + FIRST_TRAUMA +	FREQ_OF_TRAUMA +
INTELLIGENCE +	INIT_COG_INHIBITION +	COG_INHIB_DEPLETION +
INIT_RELIGIOUS_INFO +	FAMILY_RELIGIOUS_IMPORTANCE +	INIT_FACT_INFO +
EVENT_INTENSITY +	START_UG_AGE +
START_PG_AGE +	END_UG_AGE +	STUDYTOPIC +	TRADITION_SELF_CONT +
INTUITIVE_THINKING_STYLE +	COGNITIVE_REFLECTION +	NEED_FOR_COGNITION +
ENV_RELIGIOUS_IMPORTANCE +	fact_resistance +	cognitive_inhibition +
factual_information +	ontological_confusion +	analytical_thinking_style, data=trimmed_data)
summary(linReg_GB2)
trimmed_data_gbelievers <- trimmed_data[,godCat:= as.factor(ifelse(godBelief > 0, "believer", "nonbeliever"))]
trimmed_data_gbelievers$godCat <- trimmed_data:= as.factor(ifelse(godBelief > 0, "believer", "nonbeliever"))
View(trimmed_data)
trimmed_data_gbelievers$godCat <- factor(ifelse(trimmed_data$godBelief > 0, "believer", "nonbeliever"))
trimmed_data_gbelievers <- trimmed_data
trimmed_data_gbelievers$godCat <- factor(ifelse(trimmed_data$godBelief > 0, "believer", "nonbeliever"))
# Compute the analysis of variance
res.aov <- aov(INTELLIGENCE ~ godCat, data = trimmed_data_gbelievers)
# Summary of the analysis
summary(res.aov)
kruskal.test(INTELLIGENCE ~ godCat, data = trimmed_data_gbelievers)
summary(kruskal.test)
kruskal.test(INTELLIGENCE ~ godCat, data = trimmed_data_gbelievers)
res.man <- manova(cbind(INTELLIGENCE, PRESENECE_OF_A, TRADITION_SELF_CONT, analytical_thinking_style) ~ godCat, data = trimmed_data_gbelievers)
res.man <- manova(cbind(INTELLIGENCE, PRESENCE_OF_A, TRADITION_SELF_CONT, analytical_thinking_style) ~ godCat, data = trimmed_data_gbelievers)
summary(res.man)
mylogit <- glm(godCat ~ PRESENCE_OF_A + FIRST_TRAUMA +	FREQ_OF_TRAUMA +
INTELLIGENCE +	INIT_COG_INHIBITION +	COG_INHIB_DEPLETION +
INIT_RELIGIOUS_INFO +	FAMILY_RELIGIOUS_IMPORTANCE +	INIT_FACT_INFO +
EVENT_INTENSITY +	START_UG_AGE +
START_PG_AGE +	END_UG_AGE +	STUDYTOPIC +	TRADITION_SELF_CONT +
INTUITIVE_THINKING_STYLE +	COGNITIVE_REFLECTION +	NEED_FOR_COGNITION +
ENV_RELIGIOUS_IMPORTANCE +	fact_resistance +	cognitive_inhibition +
factual_information +	ontological_confusion +	analytical_thinking_style, data = trimmed_data, family = "binomial")
mylogit <- glm(godCat ~ PRESENCE_OF_A + FIRST_TRAUMA +	FREQ_OF_TRAUMA +
INTELLIGENCE +	INIT_COG_INHIBITION +	COG_INHIB_DEPLETION +
INIT_RELIGIOUS_INFO +	FAMILY_RELIGIOUS_IMPORTANCE +	INIT_FACT_INFO +
EVENT_INTENSITY +	START_UG_AGE +
START_PG_AGE +	END_UG_AGE +	STUDYTOPIC +	TRADITION_SELF_CONT +
INTUITIVE_THINKING_STYLE +	COGNITIVE_REFLECTION +	NEED_FOR_COGNITION +
ENV_RELIGIOUS_IMPORTANCE +	fact_resistance +	cognitive_inhibition +
factual_information +	ontological_confusion +	analytical_thinking_style, data = trimmed_data_gbelievers, family = "binomial")
summary(mylogit)
confint(mylogit)
train <- trimmed_data_gbelievers[1:15000,]
test <- trimmed_data_gbelievers[15001:20000,]
model <- glm(godCat ~.,family=binomial(link='logit'),data=train)
model <- glm(godBelief ~.,family=binomial(link='logit'),data=train)
model <- glm(godCat ~.,family=quasibinomial,data=train)
summary(model)
trimmed_data_gbelievers$godCat <- factor(ifelse(trimmed_data$godBelief > 3, "believer", "nonbeliever"))
train <- trimmed_data_gbelievers[1:15000,]
test <- trimmed_data_gbelievers[15001:20000,]
model <- glm(godCat ~.,family=quasibinomial,data=train)
summary(model)
trimmed_data_gbelievers$godCat <- factor(ifelse(trimmed_data$godBelief > 5, "believer", "nonbeliever"))
train <- trimmed_data_gbelievers[1:15000,]
test <- trimmed_data_gbelievers[15001:20000,]
model <- glm(godCat ~.,family=quasibinomial,data=train)
summary(model)
View(trimmed_data)
trimmed_data_gbelievers$godCat <- factor(ifelse(trimmed_data$godBelief > 100, "believer", "nonbeliever"))
train <- trimmed_data_gbelievers[1:15000,]
test <- trimmed_data_gbelievers[15001:20000,]
model <- glm(godCat ~.,family=quasibinomial,data=train)
summary(model)
mylogit <- glm(godCat ~ PRESENCE_OF_A + FIRST_TRAUMA +	FREQ_OF_TRAUMA +
INTELLIGENCE +	INIT_COG_INHIBITION +	COG_INHIB_DEPLETION +
INIT_RELIGIOUS_INFO +	FAMILY_RELIGIOUS_IMPORTANCE +	INIT_FACT_INFO +
EVENT_INTENSITY +	START_UG_AGE +
START_PG_AGE +	END_UG_AGE +	STUDYTOPIC +	TRADITION_SELF_CONT +
INTUITIVE_THINKING_STYLE +	COGNITIVE_REFLECTION +	NEED_FOR_COGNITION +
ENV_RELIGIOUS_IMPORTANCE +	fact_resistance +	cognitive_inhibition +
factual_information +	ontological_confusion +	analytical_thinking_style, data = trimmed_data_gbelievers, family = "binomial")
summary(mylogit)
# now the same analysis without cognitive inhibition:
trimmed_data3 <- trimmed_data[, c(1:20,22:25)]
df<- data.table(trimmed_data3)
head(df[,godCat:= as.factor(ifelse(godBelief > 0, "believer", "nonbeliever"))])
DF3<-df
train_xg <- df[1:15000,]
test_xg <- df[15001:20000,]
#sparse_matrix <- sparse.model.matrix(godBelief ~ ., data = df)[,-1]
dftrain<-train_xg
dftest<-test_xg
dftest2<-dftest
#output_vector = df[,godBelief] == "Marked"
sparse_matrix <- sparse.model.matrix(godCat~.-1, data = df)
output_vector = df[,godCat] == "Marked"
bst <- xgboost(data = sparse_matrix, label = output_vector, max.depth = 4,eta = 1, nthread = 2, nrounds = 10,objective = "binary:logistic")
importance <- xgb.importance(feature_names = sparse_matrix@Dimnames[[2]], model = bst)
head(importance)
bst <- xgboost(data = sparse_matrix, label = output_vector, max.depth = 4,eta = 1, nthread = 2, nrounds = 10,objective = "reg:logistic")
importance <- xgb.importance(feature_names = sparse_matrix@Dimnames[[2]], model = bst)
nodeData = read.csv('C:\Users\jelane\Google Drive\Field Mapping CMAC\CitationNetworkNodeData.csv', header = TRUE)
nodeData = read.csv('C:/Users/jelane/Google Drive/Field Mapping CMAC/CitationNetworkNodeData.csv', header = TRUE)
publicationData = read.csv('C:/Users/jelane/Google Drive/Field Mapping CMAC/20190601 ItemsALLdata.csv', header = TRUE)
combined_df <- merge(nodeData, publicationData, by.x = "Label", by.y = "itemID")
View(combined_df)
library(xlsx)
install.packages("xlsx")
library(xlsx)
write.xlsx(combined_df, "C:/Users/jelane/Google Drive/Field Mapping CMAC/combinedData_pubsNodes.xlsx")
install.packages("openxlsx")
library(openxlsx)
write.xlsx(combined_df, "C:/Users/jelane/Google Drive/Field Mapping CMAC/combinedData_pubsNodes.xlsx")
library(mongolite)
client <- "testClient"
campaign <- "testCampaign2019"
# this connects to local database
con = mongo(collection="redditdata_test", db="VOSA_test")
con2 = mongo(collection="campaigns_test", db="VOSA_test")
olddata <- con2$find('{}')
olddata
View(olddata)
campaignStartTimeStamp <- Sys.time()
lastCampaignUpdateTimeStamp <- list(Sys.time())
campaignStartDate <- Sys.Date()
campaignDataframe <- data.frame(client, campaign, lastCampaignUpdateTimeStamp, campaignStartDate, campaignStartTimeStamp, stringsAsFactors=FALSE)
View(campaignDataframe)
lastCampaignUpdateTimeStamp
View(campaignDataframe)
View(campaignDataframe)
View(olddata)
client <- "testClient"
campaign <- "testCampaign2019"
# this connects to local database
con = mongo(collection="redditdata_test", db="VOSA_test")
con2 = mongo(collection="campaigns_test", db="VOSA_test")
olddata <- con2$find('{}')
con2$count()
library(mongolite)
client <- "testClient"
campaign <- "testCampaign2019"
# this connects to local database
con = mongo(collection="redditdata_test", db="VOSA_test")
con2 = mongo(collection="campaigns_test", db="VOSA_test")
if (con2$count() > 0) {
olddata <- con2$find('{}')
}
if (con2$count() == 0) {
# wrap the campaign data in and insert it into the database
campaignStartTimeStamp <- Sys.time()
lastCampaignUpdateTimeStamp <- list()
lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, Sys.time())
campaignStartDate <- Sys.Date()
campaignDataframe <- data.frame(client, campaign, lastCampaignUpdateTimeStamp, campaignStartDate, campaignStartTimeStamp, stringsAsFactors=FALSE)
con2$insert(campaignDataframe)
}
View(campaignDataframe)
Sys.time()
typeof(Sys.time())
t <- Sys.time()
t
as.POSIXct(t)
as.POSIXlt(t)
cat(t)
if (con2$count() == 0) {
# wrap the campaign data in and insert it into the database
campaignStartTimeStamp <- Sys.time()
lastCampaignUpdateTimeStamp <- list(cat(Sys.time()))
#lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, Sys.time())
campaignStartDate <- Sys.Date()
campaignDataframe <- data.frame(client, campaign, lastCampaignUpdateTimeStamp, campaignStartDate, campaignStartTimeStamp, stringsAsFactors=FALSE)
con2$insert(campaignDataframe)
}
lastCampaignUpdateTimeStamp <- list(cat(Sys.time()))
lastCampaignUpdateTimeStamp
lastCampaignUpdateTimeStamp <- list(cat(Sys.time()))
list(cat(Sys.time()))
campaignStartTimeStamp <- Sys.time()
lastCampaignUpdateTimeStamp <- list()
lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, cat(campaignStartTimeStamp))
campaignStartDate <- Sys.Date()
campaignDataframe <- data.frame(client, campaign, lastCampaignUpdateTimeStamp, campaignStartDate, campaignStartTimeStamp, stringsAsFactors=FALSE)
lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, as.POSIXct(campaignStartTimeStamp))
campaignStartDate <- Sys.Date()
campaignDataframe <- data.frame(client, campaign, lastCampaignUpdateTimeStamp, campaignStartDate, campaignStartTimeStamp, stringsAsFactors=FALSE)
View(campaignDataframe)
library(mongolite)
client <- "testClient"
campaign <- "testCampaign2019"
# open connection to mongodb
# now get last client data from mongoDB
# this connects to local database
con = mongo(collection="redditdata_test", db="VOSA_test")
con2 = mongo(collection="campaigns_test", db="VOSA_test")
if (con2$count() > 0) {
olddata <- con2$find('{}')
}
if (con2$count() == 0) {
# wrap the campaign data in and insert it into the database
campaignStartTimeStamp <- Sys.time()
lastCampaignUpdateTimeStamp <- list()
lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, as.POSIXct(campaignStartTimeStamp))
campaignStartDate <- Sys.Date()
campaignDataframe <- data.frame(client, campaign, lastCampaignUpdateTimeStamp, campaignStartDate, campaignStartTimeStamp, stringsAsFactors=FALSE)
con2$insert(campaignDataframe)
}
lastCampaignUpdateTimeStamp
campaignStartTimeStamp <- Sys.time()
lastCampaignUpdateTimeStamp <- list()
lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, as.POSIXct(campaignStartTimeStamp))
lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, as.POSIXct(campaignStartTimeStamp))
lastCampaignUpdateTimeStamp
campaignStartDate <- Sys.Date()
campaignDataframe <- data.frame(client, campaign, lastCampaignUpdateTimeStamp, campaignStartDate, campaignStartTimeStamp, stringsAsFactors=FALSE)
con2$insert(campaignDataframe)
View(campaignDataframe)
as.Date.numeric(Sys.time())
system.time()
Sys.time()
format(Sys.time(), "%a %b %d %X %Y")
campaignStartTimeStamp <- format(Sys.time(), "%a %b %d %X %Y")
lastCampaignUpdateTimeStamp <- list()
lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, campaignStartTimeStamp)
campaignDataframe <- data.frame(client, campaign, lastCampaignUpdateTimeStamp, campaignStartTimeStamp, stringsAsFactors=FALSE)
View(campaignDataframe)
lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, campaignStartTimeStamp)
View(lastCampaignUpdateTimeStamp)
View(campaignDataframe)
lastCampaignUpdateTimeStamp
colnames(campaignDataframe) <- c("client", "campaign", "lastCampaignUpdateTimeStamp", "campaignStartTimeStamp")
View(campaignDataframe)
if (con2$count() > 0) {
prevCampaignData <- con2$find('{}')
}
if (con2$count() == 0) {
# wrap the campaign data in and insert it into the database
campaignStartTimeStamp <- format(Sys.time(), "%a %b %d %X %Y")
lastCampaignUpdateTimeStamp <- list()
lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, campaignStartTimeStamp)
#campaignStartDate <- format(Sys.time(), "%a %b %d %X %Y")
campaignDataframe <- data.frame(client, campaign, lastCampaignUpdateTimeStamp, campaignStartTimeStamp, stringsAsFactors=FALSE)
colnames(campaignDataframe) <- c("client", "campaign", "lastCampaignUpdateTimeStamp", "campaignStartTimeStamp")
con2$insert(campaignDataframe)
}
if (con2$count() > 0) {
prevCampaignData <- con2$find('{}')
}
if (con2$count() == 0) {
# wrap the campaign data in and insert it into the database
campaignStartTimeStamp <- format(Sys.time(), "%a %b %d %X %Y")
lastCampaignUpdateTimeStamp <- list()
lastCampaignUpdateTimeStamp <- c(lastCampaignUpdateTimeStamp, campaignStartTimeStamp)
#campaignStartDate <- format(Sys.time(), "%a %b %d %X %Y")
campaignDataframe <- data.frame(client, campaign, lastCampaignUpdateTimeStamp, campaignStartTimeStamp, stringsAsFactors=FALSE)
colnames(campaignDataframe) <- c("client", "campaign", "lastCampaignUpdateTimeStamp", "campaignStartTimeStamp")
con2$insert(campaignDataframe)
}
prevCampaignData <- con2$find('{"client": client, "campaign": campaign}')
prevCampaignData <- con2$find(paste0('{"client": client, "campaign": campaign}'))
prevCampaignData <- con2$find(paste0('{"client" :', client, '"campaign" :', campaign'}'))
prevCampaignData <- con2$find(paste0('{"client" :', client'}'))
paste0('{"client" :', client'}')
q <- sprintf('{ "client": %s, "campaign": %s', client, campaign)
q
q <- sprintf('{ \"client": %s, "campaign": %s', client, campaign)
q
q <- sprintf('{ \\"client": %s, "campaign": %s', client, campaign)
q
q <- sprintf('{ "client": %s, "campaign": %s', client, campaign)
q <- sprintf("{ \"client\": %s, \"campaign\": %s", client, campaign)
q
cat(q)
q <- sprintf("{ \"client\": %s, \"campaign\": %s }", client, campaign)
cat(q)
q <- sprintf("{ \"client\": %s, \"campaign\": %s }", client, campaign)
prevCampaignData <- con2$find(q)
jsonlite::fromJSON(q)
q <- sprintf("{ \"client\": \"%s\", \"campaign\": \"%s\" }", client, campaign)
jsonlite::fromJSON(q)
prevCampaignData <- con2$find(q)
View(prevCampaignData)
library(RedditExtractoR)
install.packages("RedditExtractoR")
install.packages("dplyr")
install.packages("quanteda")
install.packages("mongolite")
install.packages("stringr")
install.packages("mongolite")
install.packages("mongolite")
install.packages("mongolite")
install.packages("mongolite")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(dplyr)
library(ggpubr)
AASDM_data = read.csv("C:\\Users\\jelane\\Google Drive\\MODRN Stuff\\Models\\analyticSDM\\analyticSDM3 - Capped3\\analyticSDM3 - Capped3\\AnalyticAtheist_20190509_w_edu.csv")
#Compute correlation
# code largely drawn from http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software
trimmed_data <- AASDM_data[, c(2:27)]
res <- cor(trimmed_data)
round(res, 2)
important_data <- AASDM_data[,c(16:27)]
library(Hmisc)
res2 <- rcorr(as.matrix(important_data))
res2
View(res2)
res2[0]
res2.r
res2[["r"]]
res2[["P"]]
install.packages("xtable")
library("xtable")
icor <- roun(cor(important_data),2)
icor <- round(cor(important_data),2)
library(xtable)
library(Hmisc)
icor<-round(cor(important_data),2)
upper<-icor
upper[upper.tri(icor)]<-""
upper<-as.data.frame(upper)
print(xtable(upper), type="html")
corstars(icor, result="html")
# x is a matrix containing the data
# method : correlation method. "pearson"" or "spearman"" is supported
# removeTriangle : remove upper or lower triangle
# results :  if "html" or "latex"
# the results will be displayed in html or latex format
corstars <-function(x, method=c("pearson", "spearman"), removeTriangle=c("upper", "lower"),
result=c("none", "html", "latex")){
#Compute correlation matrix
require(Hmisc)
x <- as.matrix(x)
correlation_matrix<-rcorr(x, type=method[1])
R <- correlation_matrix$r # Matrix of correlation coeficients
p <- correlation_matrix$P # Matrix of p-value
## Define notions for significance levels; spacing is important.
mystars <- ifelse(p < .0001, "****", ifelse(p < .001, "*** ", ifelse(p < .01, "**  ", ifelse(p < .05, "*   ", "    "))))
## trunctuate the correlation matrix to two decimal
R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
## build a new matrix that includes the correlations with their apropriate stars
Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
diag(Rnew) <- paste(diag(R), " ", sep="")
rownames(Rnew) <- colnames(x)
colnames(Rnew) <- paste(colnames(x), "", sep="")
## remove upper triangle of correlation matrix
if(removeTriangle[1]=="upper"){
Rnew <- as.matrix(Rnew)
Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
Rnew <- as.data.frame(Rnew)
}
## remove lower triangle of correlation matrix
else if(removeTriangle[1]=="lower"){
Rnew <- as.matrix(Rnew)
Rnew[lower.tri(Rnew, diag = TRUE)] <- ""
Rnew <- as.data.frame(Rnew)
}
## remove last column and return the correlation matrix
Rnew <- cbind(Rnew[1:length(Rnew)-1])
if (result[1]=="none") return(Rnew)
else{
if(result[1]=="html") print(xtable(Rnew), type="html")
else print(xtable(Rnew), type="latex")
}
}
corstars(icor, result="html")
icorBIG<-round(cor(AASDM_data),2)
corstars(icorBIG, result="html")
View(trimmed_data)
icorBIG<-round(cor(trimmed_data),2)
corstars(icorBIG, result="html")
linReg_GB1_st <- lm(godBelief ~ INTELLIGENCE +	TRADITION_SELF_CONT + INTUITIVE_THINKING_STYLE +	COGNITIVE_REFLECTION +	NEED_FOR_COGNITION +
fact_resistance +	cognitive_inhibition +
ontological_confusion, data=trimmed_data)
summary(linReg_SB1_st)
linReg_GB1_st <- lm(godBelief ~ INTELLIGENCE +	TRADITION_SELF_CONT + INTUITIVE_THINKING_STYLE +	COGNITIVE_REFLECTION +	NEED_FOR_COGNITION +
fact_resistance +	cognitive_inhibition +
ontological_confusion, data=trimmed_data)
summary(linReg_GB1_st)
linReg_SB1_st_sc <- lm(scaled(supernaturalBelief) ~ scaled(INTELLIGENCE) +
scaled(TRADITION_SELF_CONT) +
scaled(INTUITIVE_THINKING_STYLE) +
scaled(COGNITIVE_REFLECTION) +
scaled(NEED_FOR_COGNITION) +
scaled(fact_resistance) +
scaled(cognitive_inhibition) +
scaled(ontological_confusion), data=trimmed_data)
linReg_SB1_st_sc <- lm(scale(supernaturalBelief) ~ scale(INTELLIGENCE) +
scale(TRADITION_SELF_CONT) +
scale(INTUITIVE_THINKING_STYLE) +
scale(COGNITIVE_REFLECTION) +
scale(NEED_FOR_COGNITION) +
scale(fact_resistance) +
scale(cognitive_inhibition) +
scale(ontological_confusion), data=trimmed_data)
summary(linReg_SB1_st_sc)
linReg_GB1_st_sc <- lm(scale(godBelief) ~ scale(INTELLIGENCE) +
scale(TRADITION_SELF_CONT) +
scale(INTUITIVE_THINKING_STYLE) +
scale(COGNITIVE_REFLECTION) +
scale(NEED_FOR_COGNITION) +
scale(fact_resistance) +
scale(cognitive_inhibition) +
scale(ontological_confusion), data=trimmed_data)
summary(linReg_GB1_st_sc)
